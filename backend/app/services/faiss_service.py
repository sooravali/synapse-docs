"""
Faiss Vector Database Service

This service manages the Faiss vector index for semantic search capabilities.
Integrates with the EmbeddingService to provide efficient similarity search.
"""
import os
import pickle
import logging
from typing import List, Dict, Tuple, Optional, Any
import numpy as np
from pathlib import Path

try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False

logger = logging.getLogger(__name__)

class FaissService:
    """
    Faiss vector database service for semantic search.
    
    Manages vector storage, indexing, and similarity search operations
    using the embeddings generated by the EmbeddingService.
    """
    
    def __init__(self, index_path: str = "data/faiss_index", embedding_dim: int = 384):
        """
        Initialize the Faiss service.
        
        Args:
            index_path: Path to store the Faiss index files
            embedding_dim: Dimension of the embeddings (384 for all-MiniLM-L6-v2)
        """
        # Convert to absolute path to avoid Docker working directory issues
        if not os.path.isabs(index_path):
            # In Docker, we want the path relative to /app
            base_path = os.getenv('FAISS_BASE_PATH', '/app')
            self.index_path = Path(base_path) / index_path
        else:
            self.index_path = Path(index_path)
            
        self.embedding_dim = embedding_dim
        self.index = None
        self.metadata = {}  # Maps index positions to chunk metadata
        self.index_file = self.index_path / "index.faiss"
        self.metadata_file = self.index_path / "metadata.pkl"
        
        # Create index directory if it doesn't exist
        self.index_path.mkdir(parents=True, exist_ok=True)
        
        # Initialize or load index
        self._initialize_index()
        
        logger.info(f"FaissService initialized with dimension {embedding_dim}")
    
    def _initialize_index(self):
        """Initialize or load the Faiss index."""
        if not FAISS_AVAILABLE:
            logger.error("Faiss not available - vector search will be disabled")
            return
        
        logger.info(f"Initializing Faiss index in directory: {self.index_path}")
        logger.info(f"Current working directory: {os.getcwd()}")
        logger.info(f"Index file path: {self.index_file}")
        logger.info(f"Metadata file path: {self.metadata_file}")

        try:
            if self.index_file.exists():
                self._load_index()
                logger.info(f"Loaded existing Faiss index with {self.get_index_size()} vectors")
            else:
                self._create_new_index()
                logger.info("Created new Faiss index")
                
        except Exception as e:
            logger.error(f"Failed to initialize Faiss index: {e}")
            self._create_new_index()
    
    def _create_new_index(self):
        """Create a new Faiss index."""
        if not FAISS_AVAILABLE:
            return
        
        # Use IndexFlatIP for cosine similarity (inner product with normalized vectors)
        self.index = faiss.IndexFlatIP(self.embedding_dim)
        self.metadata = {}
        logger.info(f"Created new Faiss IndexFlatIP with dimension {self.embedding_dim}")
    
    def _load_index(self):
        """Load existing Faiss index and metadata."""
        if not FAISS_AVAILABLE:
            return
        
        try:
            # Load the Faiss index
            self.index = faiss.read_index(str(self.index_file))
            
            # Load metadata
            if self.metadata_file.exists():
                with open(self.metadata_file, 'rb') as f:
                    self.metadata = pickle.load(f)
            else:
                self.metadata = {}
            
            logger.info(f"Loaded Faiss index: {self.get_index_size()} vectors, {len(self.metadata)} metadata entries")
            
        except Exception as e:
            logger.error(f"Failed to load Faiss index: {e}")
            self._create_new_index()
    
    def _save_index(self):
        """Save the Faiss index and metadata to disk."""
        if not FAISS_AVAILABLE or not self.index:
            return
        
        try:
            # Save the Faiss index
            faiss.write_index(self.index, str(self.index_file))
            
            # Save metadata
            with open(self.metadata_file, 'wb') as f:
                pickle.dump(self.metadata, f)
            
            logger.info(f"Saved Faiss index with {self.get_index_size()} vectors")
            
        except Exception as e:
            logger.error(f"Failed to save Faiss index: {e}")
    
    def add_embeddings(self, embeddings: List[List[float]], 
                      chunk_metadata: List[Dict[str, Any]]) -> List[int]:
        """
        Add embeddings to the Faiss index.
        
        Args:
            embeddings: List of embedding vectors
            chunk_metadata: List of metadata dicts for each embedding
            
        Returns:
            List of index positions where embeddings were added
        """
        if not FAISS_AVAILABLE or not self.index:
            logger.error("Faiss not available")
            return []
        
        if len(embeddings) != len(chunk_metadata):
            logger.error("Embeddings and metadata lists must have same length")
            return []
        
        try:
            # Convert to numpy array and normalize for cosine similarity
            embeddings_array = np.array(embeddings, dtype=np.float32)
            
            # Normalize vectors for cosine similarity with IndexFlatIP
            faiss.normalize_L2(embeddings_array)
            
            # Get current index size (starting positions for new embeddings)
            start_position = self.index.ntotal
            
            # Add to index
            self.index.add(embeddings_array)
            
            # Store metadata
            positions = []
            for i, metadata in enumerate(chunk_metadata):
                position = start_position + i
                self.metadata[position] = metadata
                positions.append(position)
            
            # Save to disk
            self._save_index()
            
            logger.info(f"Added {len(embeddings)} embeddings to Faiss index")
            return positions
            
        except Exception as e:
            logger.error(f"Failed to add embeddings to Faiss index: {e}")
            return []
    
    def add_single_embedding(self, embedding: List[float], 
                           chunk_metadata: Dict[str, Any]) -> Optional[int]:
        """
        Add a single embedding to the index.
        
        Args:
            embedding: Single embedding vector
            chunk_metadata: Metadata for the chunk
            
        Returns:
            Index position where embedding was added, or None if failed
        """
        positions = self.add_embeddings([embedding], [chunk_metadata])
        return positions[0] if positions else None
    
    def search(self, query_embedding: List[float], top_k: int = 5, 
              similarity_threshold: float = 0.5) -> List[Dict[str, Any]]:
        """
        Search for similar embeddings.
        
        Args:
            query_embedding: Query embedding vector
            top_k: Number of results to return
            similarity_threshold: Minimum similarity score
            
        Returns:
            List of search results with metadata and scores
        """
        if not FAISS_AVAILABLE or not self.index:
            logger.error("Faiss not available")
            return []
        
        if self.index.ntotal == 0:
            logger.warning("Faiss index is empty")
            logger.info(f"Index file exists: {self.index_file.exists()}")
            logger.info(f"Metadata file exists: {self.metadata_file.exists()}")
            logger.info(f"Current working directory: {os.getcwd()}")
            logger.info(f"Index path: {self.index_path}")
            
            # Try to reload the index
            if self.index_file.exists():
                logger.info("Index file exists, attempting to reload...")
                try:
                    self._load_index()
                    logger.info(f"Successfully reloaded index with {self.get_index_size()} vectors")
                except Exception as e:
                    logger.error(f"Failed to reload index: {e}")
                    return []
            else:
                logger.warning("No index file found on disk")
                return []
        
        try:
            # Convert to numpy array and normalize
            query_array = np.array([query_embedding], dtype=np.float32)
            faiss.normalize_L2(query_array)
            
            # Search the index
            scores, indices = self.index.search(query_array, top_k)
            
            # Process results
            results = []
            for score, idx in zip(scores[0], indices[0]):
                # Skip invalid indices
                if idx == -1:
                    continue
                
                # Check similarity threshold
                if score < similarity_threshold:
                    continue
                
                # Get metadata
                metadata = self.metadata.get(idx, {})
                
                result = {
                    'faiss_index_position': int(idx),
                    'similarity_score': float(score),
                    **metadata
                }
                results.append(result)
            
            logger.info(f"Faiss search returned {len(results)} results")
            return results
            
        except Exception as e:
            logger.error(f"Faiss search failed: {e}")
            return []
    
    def remove_embeddings(self, positions: List[int]) -> bool:
        """
        Remove embeddings from the index.
        Note: Faiss doesn't support direct removal, so this rebuilds the index.
        
        Args:
            positions: List of index positions to remove
            
        Returns:
            True if successful, False otherwise
        """
        if not FAISS_AVAILABLE or not self.index:
            logger.error("Faiss not available")
            return False
        
        try:
            # Get all current embeddings
            all_embeddings = []
            new_metadata = {}
            new_position = 0
            
            for i in range(self.index.ntotal):
                if i not in positions:
                    # Reconstruct embedding from index
                    embedding = self.index.reconstruct(i)
                    all_embeddings.append(embedding)
                    
                    # Update metadata with new position
                    if i in self.metadata:
                        new_metadata[new_position] = self.metadata[i]
                        new_position += 1
            
            # Create new index
            self._create_new_index()
            
            # Re-add embeddings if any remain
            if all_embeddings:
                embeddings_array = np.array(all_embeddings, dtype=np.float32)
                self.index.add(embeddings_array)
                self.metadata = new_metadata
            
            # Save to disk
            self._save_index()
            
            logger.info(f"Removed {len(positions)} embeddings from Faiss index")
            return True
            
        except Exception as e:
            logger.error(f"Failed to remove embeddings from Faiss index: {e}")
            return False
    
    def get_embedding_by_position(self, position: int) -> Optional[Tuple[List[float], Dict[str, Any]]]:
        """
        Get embedding and metadata by index position.
        
        Args:
            position: Index position
            
        Returns:
            Tuple of (embedding, metadata) or None if not found
        """
        if not FAISS_AVAILABLE or not self.index:
            return None
        
        if position >= self.index.ntotal or position < 0:
            return None
        
        try:
            embedding = self.index.reconstruct(position)
            metadata = self.metadata.get(position, {})
            return embedding.tolist(), metadata
            
        except Exception as e:
            logger.error(f"Failed to get embedding at position {position}: {e}")
            return None
    
    def get_index_size(self) -> int:
        """Get the number of vectors in the index."""
        if not FAISS_AVAILABLE or not self.index:
            return 0
        return self.index.ntotal
    
    def clear_index(self) -> bool:
        """Clear all embeddings from the index."""
        try:
            self._create_new_index()
            self._save_index()
            logger.info("Cleared Faiss index")
            return True
            
        except Exception as e:
            logger.error(f"Failed to clear Faiss index: {e}")
            return False
    
    def reload_index(self) -> bool:
        """
        Reload the index from disk.
        
        This is useful when the index files have been updated by another process
        or when you need to refresh the in-memory index.
        
        Returns:
            True if successful, False otherwise
        """
        try:
            if self.index_file.exists():
                self._load_index()
                logger.info(f"Reloaded Faiss index with {self.get_index_size()} vectors")
                return True
            else:
                logger.warning("No index file found to reload")
                self._create_new_index()
                return True
                
        except Exception as e:
            logger.error(f"Failed to reload Faiss index: {e}")
            return False
    
    def rebuild_index(self, embeddings_and_metadata: List[Tuple[List[float], Dict[str, Any]]]) -> bool:
        """
        Rebuild the index from scratch with new embeddings.
        
        Args:
            embeddings_and_metadata: List of (embedding, metadata) tuples
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Clear current index
            self.clear_index()
            
            if not embeddings_and_metadata:
                return True
            
            # Extract embeddings and metadata
            embeddings = [item[0] for item in embeddings_and_metadata]
            metadata_list = [item[1] for item in embeddings_and_metadata]
            
            # Add all embeddings
            positions = self.add_embeddings(embeddings, metadata_list)
            
            logger.info(f"Rebuilt Faiss index with {len(positions)} embeddings")
            return len(positions) == len(embeddings)
            
        except Exception as e:
            logger.error(f"Failed to rebuild Faiss index: {e}")
            return False
    
    def get_index_info(self) -> Dict[str, Any]:
        """Get information about the current index."""
        info = {
            'faiss_available': FAISS_AVAILABLE,
            'index_initialized': self.index is not None,
            'embedding_dimension': self.embedding_dim,
            'index_size': self.get_index_size(),
            'metadata_entries': len(self.metadata),
            'index_file_exists': self.index_file.exists(),
            'metadata_file_exists': self.metadata_file.exists()
        }
        
        if FAISS_AVAILABLE and self.index:
            info.update({
                'index_type': type(self.index).__name__,
                'is_trained': self.index.is_trained,
                'metric_type': 'cosine_similarity'
            })
        
        return info
    
    def health_check(self) -> Dict[str, Any]:
        """Perform a health check on the Faiss service."""
        try:
            info = self.get_index_info()
            
            # Test basic functionality if index exists
            if self.index and self.get_index_size() > 0:
                # Try a dummy search
                dummy_embedding = [0.0] * self.embedding_dim
                results = self.search(dummy_embedding, top_k=1)
                test_search_success = True
            else:
                test_search_success = True  # Empty index is OK
            
            return {
                'status': 'healthy' if test_search_success else 'degraded',
                'faiss_available': FAISS_AVAILABLE,
                'index_operational': self.index is not None,
                'test_search_success': test_search_success,
                **info
            }
            
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e),
                'faiss_available': FAISS_AVAILABLE
            }
