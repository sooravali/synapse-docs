"""
Faiss Vector Database Service

This service manages the Faiss vector index for semantic search capabilities.
Integrates with the EmbeddingService to provide efficient similarity search.
"""
import os
import pickle
import logging
from typing import List, Dict, Tuple, Optional, Any
import numpy as np
from pathlib import Path

try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False

logger = logging.getLogger(__name__)

class FaissService:
    """
    Session-aware Faiss vector database service for semantic search.
    
    Manages vector storage, indexing, and similarity search operations
    using the embeddings generated by the EmbeddingService.
    
    Each session gets its own isolated Faiss index for true multi-user isolation.
    """
    
    def __init__(self, index_path: str = "data/faiss_index", embedding_dim: int = 384):
        """
        Initialize the Faiss service.
        
        Args:
            index_path: Path to store the Faiss index files
            embedding_dim: Dimension of the embeddings (384 for all-MiniLM-L6-v2)
        """
        # Convert to absolute path to avoid Docker working directory issues
        if not os.path.isabs(index_path):
            # In Docker, we want the path relative to /app
            base_path = os.getenv('FAISS_BASE_PATH', '/app')
            self.base_index_path = Path(base_path) / index_path
        else:
            self.base_index_path = Path(index_path)
            
        self.embedding_dim = embedding_dim
        
        # Session-specific state - will be set when session is specified
        self.current_session_id = None
        self.index = None
        self.metadata = {}  # Maps index positions to chunk metadata
        self.index_file = None
        self.metadata_file = None
        
        # Create base index directory if it doesn't exist
        self.base_index_path.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Session-aware FaissService initialized with dimension {embedding_dim}")
    
    def set_session(self, session_id: str):
        """
        Set the current session and load/create the corresponding index.
        
        Args:
            session_id: Unique session identifier for user isolation
        """
        if self.current_session_id == session_id:
            # Already using this session
            return
            
        self.current_session_id = session_id
        
        # Set session-specific file paths
        session_path = self.base_index_path / f"session_{session_id}"
        session_path.mkdir(parents=True, exist_ok=True)
        
        self.index_file = session_path / "index.faiss" 
        self.metadata_file = session_path / "metadata.pkl"
        
        # Load or create session-specific index
        self._initialize_session_index()
        
        logger.info(f"Switched to session {session_id}, index size: {self.get_index_size()}")
    
    def _initialize_session_index(self):
        """Initialize or load the session-specific Faiss index."""
        if not FAISS_AVAILABLE:
            logger.error("Faiss not available - vector search will be disabled")
            return
        
        if not self.current_session_id:
            logger.error("No session ID set - call set_session() first")
            return
        
        logger.info(f"Initializing Faiss index for session: {self.current_session_id}")
        logger.info(f"Index file path: {self.index_file}")
        logger.info(f"Metadata file path: {self.metadata_file}")

        try:
            if self.index_file and self.index_file.exists():
                self._load_index()
                logger.info(f"Loaded existing session index with {self.get_index_size()} vectors")
            else:
                self._create_new_index()
                logger.info("Created new session index")
                
        except Exception as e:
            logger.error(f"Failed to initialize session index: {e}")
            self._create_new_index()
    
    def _initialize_index(self):
        """Legacy method - now delegates to session-based initialization.""" 
        # This method is kept for backward compatibility but doesn't do anything
        # All initialization is now handled by set_session()
        logger.info("Legacy _initialize_index called - use set_session() instead")
    
    def _create_new_index(self):
        """Create a new Faiss index."""
        if not FAISS_AVAILABLE:
            return
        
        # Use IndexFlatIP for cosine similarity (inner product with normalized vectors)
        self.index = faiss.IndexFlatIP(self.embedding_dim)
        self.metadata = {}
        logger.info(f"Created new Faiss IndexFlatIP with dimension {self.embedding_dim}")
    
    def _load_index(self):
        """Load existing Faiss index and metadata."""
        if not FAISS_AVAILABLE:
            return
        
        try:
            # Load the Faiss index
            self.index = faiss.read_index(str(self.index_file))
            
            # Load metadata
            if self.metadata_file.exists():
                with open(self.metadata_file, 'rb') as f:
                    self.metadata = pickle.load(f)
            else:
                self.metadata = {}
            
            logger.info(f"Loaded Faiss index: {self.get_index_size()} vectors, {len(self.metadata)} metadata entries")
            
        except Exception as e:
            logger.error(f"Failed to load Faiss index: {e}")
            self._create_new_index()
    
    def _save_index(self):
        """Save the Faiss index and metadata to disk."""
        if not FAISS_AVAILABLE or not self.index:
            return
        
        try:
            # Save the Faiss index
            faiss.write_index(self.index, str(self.index_file))
            
            # Save metadata
            with open(self.metadata_file, 'wb') as f:
                pickle.dump(self.metadata, f)
            
            logger.info(f"Saved Faiss index with {self.get_index_size()} vectors")
            
        except Exception as e:
            logger.error(f"Failed to save Faiss index: {e}")
    
    def add_embeddings(self, embeddings: List[List[float]], 
                      chunk_metadata: List[Dict[str, Any]], 
                      session_id: str = None) -> List[int]:
        """
        Add embeddings to the session-specific Faiss index.
        
        Args:
            embeddings: List of embedding vectors
            chunk_metadata: List of metadata dicts for each embedding
            session_id: Session ID for isolation (optional if already set)
            
        Returns:
            List of index positions where embeddings were added
        """
        # Set session if provided
        if session_id:
            self.set_session(session_id)
        
        if not self.current_session_id:
            logger.error("No session set - call set_session() first")
            return []
            
        if not FAISS_AVAILABLE or not self.index:
            logger.error("Faiss not available")
            return []
        
        if len(embeddings) != len(chunk_metadata):
            logger.error("Embeddings and metadata lists must have same length")
            return []
        
        try:
            # Convert to numpy array and normalize for cosine similarity
            embeddings_array = np.array(embeddings, dtype=np.float32)
            
            # Normalize vectors for cosine similarity with IndexFlatIP
            faiss.normalize_L2(embeddings_array)
            
            # Get current index size (starting positions for new embeddings)
            start_position = self.index.ntotal
            
            # Add to index
            self.index.add(embeddings_array)
            
            # Store metadata
            positions = []
            for i, metadata in enumerate(chunk_metadata):
                position = start_position + i
                self.metadata[position] = metadata
                positions.append(position)
            
            # Save to disk
            self._save_index()
            
            logger.info(f"Added {len(embeddings)} embeddings to Faiss index")
            return positions
            
        except Exception as e:
            logger.error(f"Failed to add embeddings to Faiss index: {e}")
            return []
    
    def add_single_embedding(self, embedding: List[float], 
                           chunk_metadata: Dict[str, Any]) -> Optional[int]:
        """
        Add a single embedding to the index.
        
        Args:
            embedding: Single embedding vector
            chunk_metadata: Metadata for the chunk
            
        Returns:
            Index position where embedding was added, or None if failed
        """
        positions = self.add_embeddings([embedding], [chunk_metadata])
        return positions[0] if positions else None
    
    def search(self, query_embedding: List[float], top_k: int = 5, 
              similarity_threshold: float = 0.5, session_id: str = None) -> List[Dict[str, Any]]:
        """
        Search for similar embeddings in the session-specific index.
        
        Args:
            query_embedding: Query embedding vector
            top_k: Number of results to return
            similarity_threshold: Minimum similarity score
            session_id: Session ID for isolation (optional if already set)
            
        Returns:
            List of search results with metadata and scores
        """
        # Set session if provided
        if session_id:
            self.set_session(session_id)
        
        if not self.current_session_id:
            logger.error("No session set - call set_session() first")
            return []
            
        if not FAISS_AVAILABLE or not self.index:
            logger.error("Faiss not available")
            return []
        
        if self.index.ntotal == 0:
            logger.warning(f"Faiss index is empty for session {self.current_session_id}")
            logger.info(f"Index file exists: {self.index_file and self.index_file.exists()}")
            logger.info(f"Metadata file exists: {self.metadata_file and self.metadata_file.exists()}")
            
            # Try to reload the session index
            if self.index_file and self.index_file.exists():
                logger.info("Index file exists, attempting to reload...")
                try:
                    self._load_index()
                    logger.info(f"Successfully reloaded index with {self.get_index_size()} vectors")
                except Exception as e:
                    logger.error(f"Failed to reload index: {e}")
                    return []
            else:
                logger.warning("No index file found for this session")
                return []
        
        try:
            # Convert to numpy array and normalize
            query_array = np.array([query_embedding], dtype=np.float32)
            faiss.normalize_L2(query_array)
            
            # Search the index
            scores, indices = self.index.search(query_array, top_k)
            
            # Process results
            results = []
            for score, idx in zip(scores[0], indices[0]):
                # Skip invalid indices
                if idx == -1:
                    continue
                
                # Check similarity threshold
                if score < similarity_threshold:
                    continue
                
                # Get metadata
                metadata = self.metadata.get(idx, {})
                
                result = {
                    'faiss_index_position': int(idx),
                    'similarity_score': float(score),
                    **metadata
                }
                results.append(result)
            
            logger.info(f"Faiss search returned {len(results)} results")
            return results
            
        except Exception as e:
            logger.error(f"Faiss search failed: {e}")
            return []
    
    def remove_embeddings(self, positions: List[int]) -> bool:
        """
        Remove embeddings from the index.
        Note: Faiss doesn't support direct removal, so this rebuilds the index.
        
        Args:
            positions: List of index positions to remove
            
        Returns:
            True if successful, False otherwise
        """
        if not FAISS_AVAILABLE or not self.index:
            logger.error("Faiss not available")
            return False
        
        try:
            # Get all current embeddings
            all_embeddings = []
            new_metadata = {}
            new_position = 0
            
            for i in range(self.index.ntotal):
                if i not in positions:
                    # Reconstruct embedding from index
                    embedding = self.index.reconstruct(i)
                    all_embeddings.append(embedding)
                    
                    # Update metadata with new position
                    if i in self.metadata:
                        new_metadata[new_position] = self.metadata[i]
                        new_position += 1
            
            # Create new index
            self._create_new_index()
            
            # Re-add embeddings if any remain
            if all_embeddings:
                embeddings_array = np.array(all_embeddings, dtype=np.float32)
                self.index.add(embeddings_array)
                self.metadata = new_metadata
            
            # Save to disk
            self._save_index()
            
            logger.info(f"Removed {len(positions)} embeddings from Faiss index")
            return True
            
        except Exception as e:
            logger.error(f"Failed to remove embeddings from Faiss index: {e}")
            return False
    
    def get_embedding_by_position(self, position: int) -> Optional[Tuple[List[float], Dict[str, Any]]]:
        """
        Get embedding and metadata by index position.
        
        Args:
            position: Index position
            
        Returns:
            Tuple of (embedding, metadata) or None if not found
        """
        if not FAISS_AVAILABLE or not self.index:
            return None
        
        if position >= self.index.ntotal or position < 0:
            return None
        
        try:
            embedding = self.index.reconstruct(position)
            metadata = self.metadata.get(position, {})
            return embedding.tolist(), metadata
            
        except Exception as e:
            logger.error(f"Failed to get embedding at position {position}: {e}")
            return None
    
    def get_index_size(self) -> int:
        """Get the number of vectors in the index."""
        if not FAISS_AVAILABLE or not self.index:
            return 0
        return self.index.ntotal
    
    def clear_index(self, session_id: str = None) -> bool:
        """Clear all embeddings from the session-specific index."""
        # Set session if provided
        if session_id:
            self.set_session(session_id)
            
        if not self.current_session_id:
            logger.error("No session set - call set_session() first")
            return False
            
        try:
            self._create_new_index()
            self._save_index()
            logger.info(f"Cleared Faiss index for session {self.current_session_id}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to clear Faiss index: {e}")
            return False
    
    def reload_index(self) -> bool:
        """
        Reload the index from disk.
        
        This is useful when the index files have been updated by another process
        or when you need to refresh the in-memory index.
        
        Returns:
            True if successful, False otherwise
        """
        try:
            if self.index_file.exists():
                self._load_index()
                logger.info(f"Reloaded Faiss index with {self.get_index_size()} vectors")
                return True
            else:
                logger.warning("No index file found to reload")
                self._create_new_index()
                return True
                
        except Exception as e:
            logger.error(f"Failed to reload Faiss index: {e}")
            return False
    
    def rebuild_index(self, embeddings_and_metadata: List[Tuple[List[float], Dict[str, Any]]]) -> bool:
        """
        Rebuild the index from scratch with new embeddings.
        
        Args:
            embeddings_and_metadata: List of (embedding, metadata) tuples
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Clear current index
            self.clear_index()
            
            if not embeddings_and_metadata:
                return True
            
            # Extract embeddings and metadata
            embeddings = [item[0] for item in embeddings_and_metadata]
            metadata_list = [item[1] for item in embeddings_and_metadata]
            
            # Add all embeddings
            positions = self.add_embeddings(embeddings, metadata_list)
            
            logger.info(f"Rebuilt Faiss index with {len(positions)} embeddings")
            return len(positions) == len(embeddings)
            
        except Exception as e:
            logger.error(f"Failed to rebuild Faiss index: {e}")
            return False
    
    def get_index_info(self) -> Dict[str, Any]:
        """Get information about the current index."""
        info = {
            'faiss_available': FAISS_AVAILABLE,
            'session_aware': True,
            'current_session': self.current_session_id,
            'index_initialized': self.index is not None,
            'embedding_dimension': self.embedding_dim,
            'index_size': self.get_index_size(),
            'metadata_entries': len(self.metadata),
            'index_file_exists': self.index_file.exists() if self.index_file else False,
            'metadata_file_exists': self.metadata_file.exists() if self.metadata_file else False
        }
        
        if FAISS_AVAILABLE and self.index:
            info.update({
                'index_type': type(self.index).__name__,
                'is_trained': self.index.is_trained,
                'metric_type': 'cosine_similarity'
            })
        
        return info
    
    def clear_session_data(self, session_id: str) -> bool:
        """
        Clear all data for a specific session.
        
        Args:
            session_id: Session ID to clear
            
        Returns:
            True if successful, False otherwise
        """
        try:
            import shutil
            session_path = self.base_index_path / f"session_{session_id}"
            
            if session_path.exists():
                shutil.rmtree(session_path)
                logger.info(f"Cleared all data for session {session_id}")
            else:
                logger.info(f"No data found for session {session_id}")
            
            # If this was the current session, reset state
            if self.current_session_id == session_id:
                self.current_session_id = None
                self.index = None
                self.metadata = {}
                self.index_file = None
                self.metadata_file = None
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to clear session data for {session_id}: {e}")
            return False
    
    def health_check(self) -> Dict[str, Any]:
        """Perform a health check on the Faiss service."""
        try:
            # For health check, we only check basic functionality
            # Session-specific operations are tested separately
            
            return {
                'status': 'healthy' if FAISS_AVAILABLE else 'degraded',
                'faiss_available': FAISS_AVAILABLE,
                'session_aware': True,
                'current_session': self.current_session_id,
                'base_path_exists': self.base_index_path.exists(),
                'embedding_dimension': self.embedding_dim
            }
            
        except Exception as e:
            return {
                'status': 'unhealthy',
                'error': str(e),
                'faiss_available': FAISS_AVAILABLE
            }
